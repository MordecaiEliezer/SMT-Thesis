{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5c7f1e-dad2-4cfc-b2fc-8b9a8ea48077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words:\n",
      "> Tagalog: 3232\n",
      "> Hiligaynon: 3412\n",
      "Iteration 1 Completed, Maximum Change: 0.9999999093183058\n",
      "Iteration 2 Completed, Maximum Change: 0.5282816118455986\n",
      "Iteration 3 Completed, Maximum Change: 0.2740332237784928\n",
      "Iteration 4 Completed, Maximum Change: 0.21703835058408566\n",
      "Iteration 5 Completed, Maximum Change: 0.1515512712946041\n",
      "Iteration 6 Completed, Maximum Change: 0.12573496692659947\n",
      "Iteration 7 Completed, Maximum Change: 0.10909316881355291\n",
      "Iteration 8 Completed, Maximum Change: 0.08756514150161365\n",
      "Iteration 9 Completed, Maximum Change: 0.06681065285038346\n",
      "Iteration 10 Completed, Maximum Change: 0.04961487117304486\n",
      "Iteration 11 Completed, Maximum Change: 0.04295371298440076\n",
      "Iteration 12 Completed, Maximum Change: 0.03593964034454211\n",
      "Iteration 13 Completed, Maximum Change: 0.02951721031707555\n",
      "Iteration 14 Completed, Maximum Change: 0.02404611496355058\n",
      "Iteration 15 Completed, Maximum Change: 0.01955710207806116\n",
      "Iteration 16 Completed, Maximum Change: 0.015996756529523593\n",
      "Iteration 17 Completed, Maximum Change: 0.014406249289071693\n",
      "Iteration 18 Completed, Maximum Change: 0.014219611613396271\n",
      "Iteration 19 Completed, Maximum Change: 0.013832968651078359\n",
      "Iteration 20 Completed, Maximum Change: 0.013276680880701996\n",
      "Iteration 21 Completed, Maximum Change: 0.012587204009168573\n",
      "Iteration 22 Completed, Maximum Change: 0.011802998835036993\n",
      "Iteration 23 Completed, Maximum Change: 0.01096102936141441\n",
      "Iteration 24 Completed, Maximum Change: 0.010094233712248324\n",
      "Iteration 25 Completed, Maximum Change: 0.009230059315882666\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense\n",
    "\n",
    "\n",
    "\n",
    "def build_translation_model(input_vocab_size, output_vocab_size, input_seq_length, output_seq_length, hidden_units):\n",
    "\n",
    "    encoder_input = Input(shape=(input_seq_length,))\n",
    "    decoder_input = Input(shape=(output_seq_length,))\n",
    "\n",
    "    encoder_embedding = Embedding(input_vocab_size, hidden_units, input_length=input_seq_length)(encoder_input)\n",
    "    decoder_embedding = Embedding(output_vocab_size, hidden_units, input_length=output_seq_length)(decoder_input)\n",
    "\n",
    "    encoder_blstm = Bidirectional(LSTM(hidden_units, return_sequences=True))(encoder_embedding)\n",
    "\n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences=True)(decoder_embedding, initial_state=encoder_blstm)\n",
    "\n",
    "    output = Dense(output_vocab_size, activation='softmax')(decoder_lstm)\n",
    "\n",
    "    model = Model([encoder_input, decoder_input], output)\n",
    "\n",
    "    return model\n",
    "\n",
    "tokenized_stores = {'fi_train': [], 'hi_train': []}\n",
    "for key in tokenized_stores:\n",
    "    file_name = \"/Users/eliezer/Documents/School/NLP_Translation/TrainS/\" + str(key)[3:] + \".\" + str(key)[0:2]\n",
    "    load = open(file_name)\n",
    "    sentences = load.read().split('\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        token_store = sentence.split(' ')\n",
    "        tokenized_stores[key].append(token_store)\n",
    "\n",
    "train_size = len(tokenized_stores['fi_train'])\n",
    "\n",
    "fi_words = {}\n",
    "hi_words = {}\n",
    "\n",
    "for key in tokenized_stores:\n",
    "    if str(key)[0] == 'f':\n",
    "        for sentence in tokenized_stores[key]:\n",
    "            for word in sentence:\n",
    "                if word in fi_words:\n",
    "                    fi_words[word] += 1\n",
    "                else:\n",
    "                    fi_words[word] = 1\n",
    "    else:\n",
    "        # Creating hi_words\n",
    "        for sentence in tokenized_stores[key]:\n",
    "            for word in sentence:\n",
    "                if word in hi_words:\n",
    "                    hi_words[word] += 1\n",
    "                else:\n",
    "                    hi_words[word] = 1\n",
    "\n",
    "fi_vocab = len(fi_words)\n",
    "hi_vocab = len(hi_words)\n",
    "print(\"Number of Unique Words:\")\n",
    "print(\"> Tagalog:\", str(fi_vocab))\n",
    "print(\"> Hiligaynon:\", str(hi_vocab))\n",
    "\n",
    "t = {}\n",
    "uniform = 1 / (fi_vocab * hi_vocab)\n",
    "n_iters = 0\n",
    "max_iters = 25\n",
    "\n",
    "fine_tune = 1\n",
    "has_converged = False\n",
    "\n",
    "while n_iters < max_iters and not has_converged:\n",
    "    has_converged = True\n",
    "    max_change = -1\n",
    "\n",
    "    n_iters += 1\n",
    "    count = {}\n",
    "    total = {}\n",
    "    for index in range(train_size):\n",
    "        s_total = {}\n",
    "        for fi_word in tokenized_stores['fi_train'][index]:\n",
    "            s_total[fi_word] = 0\n",
    "            for hi_word in tokenized_stores['hi_train'][index]:\n",
    "                if (fi_word, hi_word) not in t:\n",
    "                    t[(fi_word, hi_word)] = uniform\n",
    "                s_total[fi_word] += t[(fi_word, hi_word)]\n",
    "\n",
    "        for fi_word in tokenized_stores['fi_train'][index]:\n",
    "            for hi_word in tokenized_stores['hi_train'][index]:\n",
    "                if (fi_word, hi_word) not in count:\n",
    "                    count[(fi_word, hi_word)] = 0\n",
    "                count[(fi_word, hi_word)] += (t[(fi_word, hi_word)] / s_total[fi_word])\n",
    "\n",
    "                if hi_word not in total:\n",
    "                    total[hi_word] = 0\n",
    "                total[hi_word] += (t[(fi_word, hi_word)] / s_total[fi_word])\n",
    "\n",
    "    # Update translation probabilities\n",
    "    for (fi_word, hi_word), _ in count.items():\n",
    "        if abs(t[(fi_word, hi_word)] - count[(fi_word, hi_word)] / total[hi_word]) > 0.005:\n",
    "            has_converged = False\n",
    "            max_change = max(max_change, abs(t[(fi_word, hi_word)] - count[(fi_word, hi_word)] / total[hi_word]))\n",
    "        t[(fi_word, hi_word)] = count[(fi_word, hi_word)] / total[hi_word]\n",
    "\n",
    "    print(f\"Iteration {n_iters} Completed, Maximum Change: {max_change}\")\n",
    "\n",
    "def translate_sentence(sentence, source_lang, target_lang):\n",
    "    translated_sentence = []\n",
    "    words = sentence.split(' ')\n",
    "    if source_lang == 'fi' and target_lang == 'hi':\n",
    "        for word in words:\n",
    "            translations = {hi_word: prob for (fi_word, hi_word), prob in t.items() if fi_word == word}\n",
    "            hi_word = max(translations, key=translations.get, default=None)\n",
    "            translated_sentence.append(hi_word if hi_word else word)\n",
    "    elif source_lang == 'hi' and target_lang == 'fi':\n",
    "        for word in words:\n",
    "            translations = {fi_word: prob for (fi_word, hi_word), prob in t.items() if hi_word == word}\n",
    "            fi_word = max(translations, key=translations.get, default=None)\n",
    "            translated_sentence.append(fi_word if fi_word else word)\n",
    "    else:\n",
    "        print(\"Invalid language codes. Please use 'fi' for Filipino and 'hi' for Hiligaynon.\")\n",
    "        return \"\"\n",
    "    return ' '.join(translated_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f074e7a7-0e9d-4e72-b54a-3877c9fc5bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your sentence:  akin yang pagkain\n",
      "Enter the source language code (fi/hi):  fi\n",
      "Enter the target language code (fi/hi):  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Sentence: magilog yang pagkaun\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sentence_to_translate = input(\"Enter your sentence: \")\n",
    "source_language = input(\"Enter the source language code (fi/hi): \")\n",
    "target_language = input(\"Enter the target language code (fi/hi): \")\n",
    "\n",
    "translated_sentence = translate_sentence(sentence_to_translate, source_language, target_language)\n",
    "print(\"Translated Sentence:\", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99134e28-0d6c-4243-a6ff-217d389214d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import tkinter.font as tkFont\n",
    "from tkinter import messagebox\n",
    "import string\n",
    "\n",
    "def translate_sentence_with_probabilities(sentence, source_lang, target_lang):\n",
    "    translated_sentence = []\n",
    "    translation_probabilities = []\n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    if source_lang == 'fi' and target_lang == 'hi':\n",
    "        for word in words:\n",
    "            translations = {hi_word: prob for (fi_word, hi_word), prob in t.items() if fi_word == word}\n",
    "            if translations:\n",
    "                hi_word, max_prob = max(translations.items(), key=lambda item: item[1])\n",
    "            else:\n",
    "                hi_word, max_prob = None, 0  # No translation found, probability is 0\n",
    "                \n",
    "            translated_sentence.append(hi_word if hi_word else word)\n",
    "            translation_probabilities.append(max_prob)\n",
    "            \n",
    "    elif source_lang == 'hi' and target_lang == 'fi':\n",
    "        for word in words:\n",
    "            translations = {fi_word: prob for (fi_word, hi_word), prob in t.items() if hi_word == word}\n",
    "            if translations:\n",
    "                fi_word, max_prob = max(translations.items(), key=lambda item: item[1])\n",
    "            else:\n",
    "                fi_word, max_prob = None, 0  # No translation found, probability is 0\n",
    "                \n",
    "            translated_sentence.append(fi_word if fi_word else word)\n",
    "            translation_probabilities.append(max_prob)\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid language codes. Please use 'fi' for Filipino and 'hi' for Hiligaynon.\") # This is for testing\n",
    "        return \"\", [], 0.0\n",
    "    \n",
    "    average_probability = sum(translation_probabilities) / len(translation_probabilities) if translation_probabilities else 0.0\n",
    "    return ' '.join(translated_sentence), translation_probabilities, average_probability\n",
    "\n",
    "def update_target_language():\n",
    "    if lang_var.get() == \"fi\":\n",
    "        source_lang = \"fi\"\n",
    "        target_lang = \"hi\"\n",
    "    else:\n",
    "        source_lang = \"hi\"\n",
    "        target_lang = \"fi\"\n",
    "    #source_lang_label.config(text=f\"Source Language: {source_lang.upper()}\")\n",
    "    #target_lang_label.config(text=f\"Target Language: {target_lang.upper()}\")\n",
    "    return source_lang, target_lang\n",
    "\n",
    "def translate():\n",
    "    # Retrieve text from the Text widget, from start to \"end-1c\" to omit the last newline character added by Text widget\n",
    "    sentence = entry_sentence.get(\"1.0\", \"end-1c\").strip().lower()\n",
    "    if not sentence:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter a sentence to translate.\")\n",
    "        return\n",
    "    if any(char in string.punctuation for char in sentence):\n",
    "        messagebox.showwarning(\"Warning\", \"The sentence must not contain punctuation.\")\n",
    "        return\n",
    "    source_lang, target_lang = update_target_language()\n",
    "    translated, probabilities, avg_probability = translate_sentence_with_probabilities(sentence, source_lang, target_lang)\n",
    "    result_label.config(text=translated)\n",
    "    avg_prob_label.config(text=f\"Average Probability: {avg_probability:.2f}\")\n",
    "\n",
    "\n",
    "def clear_text():\n",
    "    entry_sentence.delete(\"1.0\", tk.END)  # Corrected indices\n",
    "    result_label.config(text=\"\")\n",
    "    avg_prob_label.config(text=\"Average Probability:\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Statistical Machine Translation\")\n",
    "root.resizable(False, False)\n",
    "root.geometry(\"1050x300\")\n",
    "\n",
    "fontobj = tkFont.Font(size=15)\n",
    "\n",
    "left_frame = tk.Frame(root)\n",
    "left_frame.pack(side=tk.LEFT, padx=10, pady=10, fill=tk.Y)\n",
    "\n",
    "middle_frame = tk.Frame(root)\n",
    "middle_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "right_frame = tk.Frame(root)\n",
    "right_frame.pack(side=tk.LEFT, padx=10, pady=10, fill=tk.Y)\n",
    "\n",
    "tk.Label(left_frame, text=\"Enter your sentence:\").pack()\n",
    "entry_sentence = tk.Text(left_frame, width=40, font=fontobj)\n",
    "entry_sentence.pack()\n",
    "\n",
    "tk.Label(middle_frame, text=\"Select the source language:\").pack()\n",
    "lang_var = tk.StringVar(value=\"fi\")\n",
    "tk.Radiobutton(middle_frame, text=\"Filipino (fi)\", variable=lang_var, value=\"fi\", command=update_target_language).pack()\n",
    "tk.Radiobutton(middle_frame, text=\"Hiligaynon (hi)\", variable=lang_var, value=\"hi\", command=update_target_language).pack()\n",
    "\n",
    "source_lang_label = tk.Label(middle_frame)\n",
    "source_lang_label.pack()\n",
    "target_lang_label = tk.Label(middle_frame)\n",
    "target_lang_label.pack()\n",
    "\n",
    "translate_button = tk.Button(middle_frame, text=\"Translate\", command=translate)\n",
    "translate_button.pack(pady=10)\n",
    "\n",
    "clear_button = tk.Button(middle_frame, text=\"Clear\", command=clear_text)\n",
    "clear_button.pack(pady=(0,10))\n",
    "\n",
    "tk.Label(right_frame, text=\"Translated Sentence:\").pack()\n",
    "result_label = tk.Label(right_frame, text=\"\", relief=tk.SUNKEN, width=45, anchor=\"nw\",height=16, font=fontobj)\n",
    "result_label.pack()\n",
    "\n",
    "avg_prob_label = tk.Label(middle_frame, text=\"Average Probability:\", relief=tk.SUNKEN, width=18, anchor=\"w\", borderwidth=0)\n",
    "avg_prob_label.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc02545-78d4-404c-8cd6-c6842b3f55e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
